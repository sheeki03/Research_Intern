#!/usr/bin/env python3
"""Automated weekly research pipeline.

This script mirrors the end-to-end workflow exercised by *tests/test_final.py*:

1. Detect project cards with a *completed* Due Diligence Questionnaire (DDQ)
   in the last 7 days (created in the last 150 days).
2. Skip any card that already has an **AI Deep Research Report** attached.
3. For each eligible card run the full pipeline:

   a. Generate markdown report via ``run_deep_research``.
   b. Publish / update the **AI Deep Research Report** page in Notion.
   c. Generate project score JSON via ``run_project_scoring``.
   d. Publish / update the ðŸ”¥ **Ratings** inline database via ``publish_ratings``.

The script is intended to be triggered as a CRON/CI job **every Monday at
00:00 CET**.  It uses only stdout logging so that the orchestrating
scheduler (cron, GitHub Actions, etc.) can capture the output.
"""
from __future__ import annotations

import os
import sys
import tempfile
from datetime import datetime, timedelta, timezone
from pathlib import Path

# Pipeline entry points -------------------------------------------------------
from src.watcher import poll_notion_db
from src.research import run_deep_research
from src.writer import publish_report, _report_already_exists  # type: ignore
from src.scorer import run_project_scoring
from src.pusher import publish_ratings


def _check_env() -> None:
    """Ensure that all required environment variables are present."""

    required = [
        "NOTION_TOKEN",
        "NOTION_DB_ID",
        "OPENAI_API_KEY",
    ]

    missing = [name for name in required if not os.getenv(name)]
    if missing:
        missing_str = ", ".join(missing)
        print(f"[ERROR] Missing environment variables: {missing_str}", file=sys.stderr)
        sys.exit(1)


def _eligible_project_pages() -> list[dict[str, str]]:
    """Return project cards ready for processing (no existing report)."""

    # Last 150-day creation window, but completed DDQ in the last week.
    since_created = datetime.now(timezone.utc) - timedelta(days=150)
    completed_after = datetime.now(timezone.utc) - timedelta(days=7)

    raw_pages = poll_notion_db(last_updated=completed_after, created_after=since_created)
    return [p for p in raw_pages if not _report_already_exists(p["page_id"])]


def _run_pipeline(page: dict[str, str], idx: int, total: int, tmp_dir: Path) -> None:
    """Execute full research â†’ writer â†’ scorer â†’ pusher chain for *page*."""

    page_id = page["page_id"]
    title = page.get("title", "Untitled")

    print(f"[{idx}/{total}] Processing: {title} ({page_id})")

    # Step 1 â€“ Deep research markdown
    md_path = tmp_dir / f"ddq_{idx}.md"
    try:
        report_path = run_deep_research(page_id, md_path)
    except Exception as exc:  # noqa: BLE001 â€“ surface but continue with next card
        print(f"      âœ– research generation failed: {exc}", file=sys.stderr)
        return

    # Step 2 â€“ Publish / update Notion report
    try:
        notion_url = publish_report(page_id, report_path)
    except Exception as exc:  # noqa: BLE001
        print(f"      âœ– report publishing failed: {exc}", file=sys.stderr)
        return

    # Step 3 â€“ Run scoring pipeline (JSON)
    try:
        json_path = run_project_scoring(page_id)
    except Exception as exc:  # noqa: BLE001
        print(f"      âœ– project scoring failed: {exc}", file=sys.stderr)
        return

    # Step 4 â€“ Push Ratings inline DB
    try:
        ratings_db_id = publish_ratings(page_id)
    except Exception as exc:  # noqa: BLE001
        print(f"      âœ– pushing ratings failed: {exc}", file=sys.stderr)
        return

    print(f"      âœ“ Report published: {notion_url}")
    print(f"      âœ“ Score JSON: {json_path}")
    print(f"      âœ“ Ratings DB ID: {ratings_db_id}\n")

    # ------------------------------------------------------------------
    # House-keeping â€“ remove local artifacts so that no files linger beyond
    # the lifetime of this script.  They were written only to facilitate
    # intermediate steps (writer & pusher) and are no longer needed.
    # ------------------------------------------------------------------
    try:
        report_path.unlink(missing_ok=True)
        json_path.unlink(missing_ok=True)
    except Exception:  # noqa: BLE001 â€“ best-effort cleanup
        pass


def main() -> None:  # noqa: D401 â€“ imperative mood preferred
    """Run the weekly research pipeline once."""

    _check_env()

    pages = _eligible_project_pages()
    if not pages:
        print("No eligible project cards found â€“ everything up-to-date.")
        return

    print("Eligible project cards (without existing report):")
    for idx, page in enumerate(pages, 1):
        print(f"  [{idx}/{len(pages)}] {page.get('title', 'Untitled')} ({page['page_id']})")

    with tempfile.TemporaryDirectory() as tmp:
        tmp_dir = Path(tmp)
        for idx, page in enumerate(pages, 1):
            _run_pipeline(page, idx, len(pages), tmp_dir)


if __name__ == "__main__":
    main()
